{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Irene32Mwaniki/AI-Storytelling-Project-/blob/main/AIPROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f21d4a19"
      },
      "source": [
        "import os\n",
        "\n",
        "# Read the API key from the environment variable\n",
        "if \"GEMINI_API_KEY\" in os.environ:\n",
        "    GEMINI_API_KEY = os.environ['GEMINI_API_KEY']\n",
        "    print(\"API key loaded from environment variable.\")\n",
        "else:\n",
        "    print(\"Error: GEMINI_API_KEY environment variable not set.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini Text Story Generator"
      ],
      "metadata": {
        "id": "JWQV-k9UfnCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rationale: To prompt the user to enter a story idea; sent to Gemini 2.5 Flash for story generation and prints the generated story"
      ],
      "metadata": {
        "id": "DoJsu5lLfsBK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MfQ7HwlcXBi"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers pillow google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9Yj0KcxcXTo"
      },
      "outputs": [],
      "source": [
        "from google import generativeai as genai\n",
        "import os\n",
        "#client=genai.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEc8xszscXcO"
      },
      "outputs": [],
      "source": [
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "  print(\"Please set your Gemini API key in the environment variable GEMINI_API_KEY\")\n",
        "else:\n",
        "  genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
        "  MODEL=\"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2QXrW8phG7X"
      },
      "outputs": [],
      "source": [
        "prompt=input(\"Enter your Story prompt and press enter:\\n\")\n",
        "if prompt.strip()==\"\":\n",
        "  print(\"No prompt entered, Exiting.\")\n",
        "else:\n",
        "    print(f\"Generating story for prompt: {prompt}\")\n",
        "    print(\"It may take a few seconds\")\n",
        "    try:\n",
        "      model = genai.GenerativeModel(model_name=MODEL)\n",
        "      resp=model.generate_content(contents=[prompt])\n",
        "      print(\"\\n----Generated Story----\\n\")\n",
        "      print(resp.text)\n",
        "    except Exception as e:\n",
        "      print(f\"Error generating story: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiT_p31RvhJp"
      },
      "source": [
        "Image Caption and Story Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To upload an image via Colab, use BLIP to create an image caption, and send the caption as a prompt to Gemini to generate a story inspired by the image"
      ],
      "metadata": {
        "id": "MYaLzlomgAUS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTL4D_5Sucai"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers pillow google-generativeai timm # pytorch image package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiIuPAL-ucMn"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "import os\n",
        "from google import genai\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-apDd0UpvjzW"
      },
      "outputs": [],
      "source": [
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "  print(\"Please set your Gemini API key in the environment variable GEMINI_API_KEY\")\n",
        "else:\n",
        "  from google import generativeai as genai\n",
        "  genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
        "  MODEL=\"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1kiZe6SxT1b"
      },
      "outputs": [],
      "source": [
        "processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDnshHgPx_Pw"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  images=Image.open(fn).convert('RGB')\n",
        "  display(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8pvmKpgzkuP"
      },
      "outputs": [],
      "source": [
        "for fn in uploaded.keys():\n",
        "    images = Image.open(fn).convert('RGB')\n",
        "    inputs = processor(images=images, return_tensors=\"pt\")\n",
        "    out = model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"Caption generated by BLIP for {fn}:\")\n",
        "    print(caption)\n",
        "    print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKuwa3l51XDy"
      },
      "outputs": [],
      "source": [
        "story_prompt=(f\"Write a short story (around 300 words) based on this scene description: {caption}\")\n",
        "print(story_prompt)\n",
        "\n",
        "print(\"Sending this to Gemini. \\n\")\n",
        "\n",
        "try:\n",
        "  model = genai.GenerativeModel(model_name=MODEL)\n",
        "  response=model.generate_content(contents=[story_prompt])\n",
        "  story=response.text\n",
        "  print(\"\\n-----Generated Story -----\\n\")\n",
        "  print(story)\n",
        "except Exception as e:\n",
        "  print(f\"Error generating story: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kibvmEzS4JpM"
      },
      "outputs": [],
      "source": [
        "with open(\"generated_story.txt\", \"w\") as f:\n",
        "  f.write(story)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"generated_story.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Image Story + GUI"
      ],
      "metadata": {
        "id": "xUGvsMPzgNwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to:\n",
        "- Upload multiple images\n",
        "- Use BLIP to generate captions for each image\n",
        "- The user needs to be able to select a tone (romatic, or sci-fi etc) and story length using ipywidgets\n",
        "- Gemini generates a multi-chapter story with outline and full text\n",
        "- saves the full story as text file"
      ],
      "metadata": {
        "id": "3dUo9jPNgRbg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpfF8_u0qy62"
      },
      "outputs": [],
      "source": [
        "!pip install -q ipywidgets google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH4cQUL9qyyM"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "images=[]\n",
        "image_names=[]\n",
        "\n",
        "for name, file in uploaded.items():\n",
        "  image=Image.open(io.BytesIO(file)).convert('RGB')\n",
        "  image_names.append(name)\n",
        "  images.append(image)\n",
        "  display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-2HD0_cBO3U"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "import os\n",
        "from google import genai\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkBe9QAztrVk"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "from google import generativeai as genai\n",
        "\n",
        "processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "blip_model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "\n",
        "captions=[]\n",
        "\n",
        "for img in images:\n",
        "  inputs=processor(images=img,return_tensors='pt')\n",
        "  out=blip_model.generate(**inputs, max_new_tokens=30)\n",
        "  caption=processor.decode(out[0],skip_special_tokens=True)\n",
        "  captions.append(caption)\n",
        "\n",
        "\n",
        "  print(\"Captions generates from images:\")\n",
        "  for i, caption in enumerate(captions):\n",
        "    print(f\"{image_names[i]}: {caption}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI_H3NINtrPn"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display , clear_output\n",
        "\n",
        "\n",
        "tone_dropdown=widgets.Dropdown(\n",
        "    options=[\"Mystery\", \"Sci-fi\", \"Horror\", \"Adventorous\", \"Romantic\"],\n",
        "    value=\"Sci-fi\",\n",
        "    description=\"Tone:\"\n",
        ")\n",
        "\n",
        "length_dropdown=widgets.Dropdown(\n",
        "    options=[\"Short(100-200 words)\", \"Medium(300-400 words)\", \"Long(500-700 words)\"],\n",
        "    value=\"Medium(300-400 words)\",\n",
        "    description=\"Length:\"\n",
        ")\n",
        "\n",
        "generate_button=widgets.Button(description=\"Generate Story\")\n",
        "output_area=widgets.Output()\n",
        "\n",
        "display(tone_dropdown, length_dropdown, generate_button, output_area)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-37M75Pi2BP9"
      },
      "outputs": [],
      "source": [
        "def on_generate_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        selected_tone = tone_dropdown.value\n",
        "        length_map = {\n",
        "            \"Short(100-200 words)\": \"100-200 words\",\n",
        "            \"Medium(300-400 words)\": \"300 - 400 words\",\n",
        "            \"Long(500-700 words)\": \"500 - 700 words\"\n",
        "        }\n",
        "        length = length_map[length_dropdown.value]\n",
        "\n",
        "        # Define MODEL here to ensure it's accessible\n",
        "        MODEL=\"gemini-2.5-flash\"\n",
        "\n",
        "        caption_prompt = \"\\n\".join([f\"-{c}\" for c in captions])\n",
        "\n",
        "        outline_prompt = (\n",
        "            f\"Using the following scene descriptions, create a 4-chapter story outline. \"\n",
        "            f\"Each chapter should have a title and a short summary.\\n\\n\"\n",
        "            f\"{caption_prompt}\\n\\nOutline:\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            model = genai.GenerativeModel(model_name=MODEL)\n",
        "            outline_response = model.generate_content(\n",
        "                contents=[outline_prompt],\n",
        "                generation_config=genai.GenerationConfig(max_output_tokens=500) # Added max_output_tokens for outline\n",
        "            )\n",
        "            outline_text = outline_response.text\n",
        "            print(\" Story Outline:\\n\")\n",
        "            print(outline_text)\n",
        "\n",
        "            full_story = \"\"\n",
        "            # Determine max_tokens based on selected length for chapters\n",
        "            chapter_max_tokens_map = {\n",
        "                \"Short(100-200 words)\": 200,\n",
        "                \"Medium(300-400 words)\": 400,\n",
        "                \"Long(500-700 words)\": 700\n",
        "            }\n",
        "            chapter_max_tokens = chapter_max_tokens_map[length_dropdown.value]\n",
        "\n",
        "\n",
        "            for i in range(1, 5):  # Assuming 4 chapters based on the outline prompt\n",
        "                chapter_prompt = (\n",
        "                    f\"Using the outline below, write Chapter {i} in a {selected_tone} tone. \"\n",
        "                    f\"Make it {length}. Add vivid details, good pacing, and consistent characters.\\n\\n\"\n",
        "                    f\"{outline_text}\\n\\nChapter {i}:\"\n",
        "                )\n",
        "                chapter_response = model.generate_content(\n",
        "                    contents=[chapter_prompt],\n",
        "                    generation_config=genai.GenerationConfig(max_output_tokens=chapter_max_tokens) # Added max_output_tokens for chapters\n",
        "                )\n",
        "                chapter_text = chapter_response.text\n",
        "                print(f\"\\n Chapter {i}: \\n\")\n",
        "                print(chapter_text)\n",
        "                full_story += f\"\\n\\nChapter {i}: \\n{chapter_text}\"\n",
        "\n",
        "            with open(\"multi_image_story.txt\", \"w\") as f:\n",
        "                f.write(full_story)\n",
        "            print(\"\\nStory saved as multi_image_story.txt\")\n",
        "\n",
        "            from google.colab import files\n",
        "            files.download(\"multi_image_story.txt\")\n",
        "        except Exception as e:\n",
        "            print(\"Error generating story: \", e)\n",
        "\n",
        "generate_button.on_click(on_generate_button_clicked)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export to PDF and Audio"
      ],
      "metadata": {
        "id": "xzBj6oQvgmB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to be able to to:\n",
        "1. Convert the generated story to a pdf file using ReportLab\n",
        "2. Conver the story text to mp3 file with different accents using gTTS\n",
        "3. To allow the user to download both audio and text from Colab"
      ],
      "metadata": {
        "id": "cdZkL4SAgl2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gtts reportlab"
      ],
      "metadata": {
        "id": "e7PwUayuT-PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_text = \"\"\"\n",
        "**Chapter 1: The Muddy Promise**\n",
        "*   **Summary:** Lily and Daisy, two inseparable friends, spend their days in joyful abandon, their laughter echoing across the field as they create elaborate mud castles. Nearby, Old Mr. Silas sits peacefully with his loyal dog, Buster, a quiet fixture in their daily lives. The girls often overhear snippets of village tales about the \"Whispering Falls\" and the mysteries hidden beyond the familiar path, sparking a shared dream of adventure that begins to overshadow their muddy play.\n",
        "\n",
        "**Chapter 2: A Glimmer of the Falls**\n",
        "*   **Summary:** Driven by their growing curiosity, Lily and Daisy decide to finally seek out the legendary Whispering Falls. They bid farewell to their usual play spot, packing a small satchel with provisions. As they venture further than ever before, they pass Mr. Silas and Buster once more. Mr. Silas, sensing their budding quest, offers a knowing smile and a cryptic word of encouragement about listening to the land. The girls follow a winding, overgrown track, their excitement building until they catch their first breathtaking glimpse of the majestic waterfall, its cascades framing a unique road carved straight through its base.\n",
        "\n",
        "**Chapter 3: The Veiled Passage**\n",
        "*   **Summary:** Standing before the powerful Whispering Falls, Lily and Daisy are awestruck by its beauty and the strange duality of the ancient water meeting the man-made road. They bravely traverse the damp, echoing passage of the road through the falls, feeling as though they are crossing a threshold into another realm. Emerging on the other side, the air feels different, the forest denser and more wild. They realize the waterfall was not an endpoint, but a gateway to a deeper, more untamed part of the world, where their true adventure begins.\n",
        "\n",
        "**Chapter 4: The Forest's Secret Keeper**\n",
        "*   **Summary:** Deeper into the ancient forest, sunlight filters through the dense canopy, dappling the mossy ground. Lily and Daisy, their senses alive with the sights and sounds of the wild, follow the rustling leaves and distant calls. Their journey culminates in a hidden clearing where, hanging playfully from a high tree branch, a curious monkey observes them with intelligent, ancient eyes. The monkey seems to be a silent guardian, a symbol of the forest's untamed spirit. The girls understand that the true \"secret\" isn't something to find, but the profound connection to nature they've experienced, leaving the forest forever changed by its wild magic.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fiDFn2MUT-Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "from gtts import gTTS\n",
        "\n",
        "\n",
        "def export_pdf(text,filename=\"story_text\"):\n",
        "  c=canvas.Canvas(f\"{filename}.pdf\",pagesize=letter)\n",
        "  width, height=letter\n",
        "  text_object=c.beginText(40,height-40)\n",
        "  text_object.setFont(\"Helvetica\",12)\n",
        "\n",
        "  for line in text.split('\\n'):\n",
        "    for subline in [line[i:i+90] for i in range(0,len(line),90)]:\n",
        "      text_object.textLine(subline)\n",
        "  c.drawText(text_object)\n",
        "  c.showPage()\n",
        "  c.save()\n",
        "\n",
        "export_pdf(story_text)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"story_text.pdf\")"
      ],
      "metadata": {
        "id": "d0kq9rUWWjxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "\n",
        "voices = {\n",
        "    \"Default English (US Female)\": {\"lang\": \"en\", \"gender\": \"female\", \"accent\": \"us\"},\n",
        "    \"Default English (US Male)\": {\"lang\": \"en\", \"gender\": \"male\", \"accent\": \"us\"},\n",
        "    \"British Accent\": { \"lang\": \"en\", \"tld\": \"co.uk\"},\n",
        "    \"Australian Accnet\": { \"lang\": \"en\", \"tld\": \"com.au\"},\n",
        "    \"Indian Accent\": { \"lang\": \"en\", \"tld\": \"co.in\"},\n",
        "    \"French Accent\": { \"lang\": \"fr\", \"tld\": \"fr\"},\n",
        "    \"Spanish Accent\": { \"lang\": \"es\", \"tld\": \"es\"},\n",
        "    \"German Accent\": { \"lang\": \"de\", \"tld\": \"de\"},\n",
        "    \"Italian Accent\": { \"lang\": \"it\", \"tld\": \"it\"},\n",
        "    \"Japanese Accent\": { \"lang\": \"ja\", \"tld\": \"jp\"},\n",
        "    \"Slow Reading Voice\": { \"lang\": \"en\", \"slow\": True}\n",
        "}\n",
        "\n",
        "for label,options in voices.items():\n",
        "  print(f\"Generating Audio: {label}\")\n",
        "\n",
        "  tts=gTTS(\n",
        "      text=story_text,\n",
        "      lang=options[\"lang\"],\n",
        "      tld=options.get(\"tld\", \"com\"),\n",
        "      slow=options.get(\"slow\", False)\n",
        "  )\n",
        "\n",
        "  filename=f\"{label.replace(' ', '_').lower()}.mp3\"\n",
        "\n",
        "  tts.save(filename)\n",
        "\n",
        "  display(Audio(filename=filename, autoplay=False))\n",
        "\n",
        "  files.download(filename)"
      ],
      "metadata": {
        "id": "0hJwiLnkWjm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit APP"
      ],
      "metadata": {
        "id": "2ub6qHGsg3vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to:\n",
        "1. Turn everything into a deployable Streamlit web app\n",
        "2. Lets the user upload images, choose the tone and story length\n",
        "3. Exports results as PDF or audio\n",
        "4. Includes optional ngrok itnegration for public sharing"
      ],
      "metadata": {
        "id": "9WwrSrI4g3j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_streamlit_story.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import io, requests, os\n",
        "import textwrap\n",
        "from gtts import gTTS\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from google import genai\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.utils import ImageReader\n",
        "from pyngrok import ngrok\n",
        "from tempfile import NamedTemporaryFile\n",
        "import google.generativeai as genai\n",
        "import torch\n",
        "\n",
        "#authentication\n",
        "NGROK_AUTH_TOKEN = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "BACKGROUND_IMAGE_URL= \"https://i.postimg.cc/t4BYWppf/Victoria-falls-1.jpg\"\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "#streamlit Page Setup\n",
        "st.set_page_config(page_title=\"StoryTeller\", layout=\"wide\")\n",
        "\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "    .stApp{{\n",
        "        background-image: url(\"{BACKGROUND_IMAGE_URL}\");\n",
        "        background-attachment: fixed;\n",
        "        background-size: cover;\n",
        "    }}\n",
        "    section[data-testid=\"stSidebar\"]{{\n",
        "        background:rgba(0,0,0,0.3);\n",
        "        background-filter:blur(10px);\n",
        "        border-radius:12px;\n",
        "        padding:10px;\n",
        "    }}\n",
        "    div[data-testid=\"stFileUploader\"]{{\n",
        "        background:rgba(255,255,255,0.2);\n",
        "        background-filter:blur(10px);\n",
        "        border-radius:12px;\n",
        "        padding:10px;\n",
        "    }}\n",
        "    html, body, h1, h2, h3, h4, h5, h6, p,div, span, label, li, input, textarea {{\n",
        "      color:#93A8AC !important;\n",
        "    }}\n",
        "    .stButton>button, .stDownloadButton>button {{\n",
        "      color:#93A8AC !important;\n",
        "      border-color:#93A8AC;\n",
        "    }}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.title(\"Multi-Image AI Storyteller\")\n",
        "st.markdown(\"Upload images - Generate story - Export as PDF & MP3\")\n",
        "\n",
        "with st.sidebar:\n",
        "  tone=st.selectbox(\"Tone\", [\"Descriptive\", \"Narrative\", \"Factual\", \"Simple\"])\n",
        "  length_label=st.selectbox(\"Length\", [\"Short (100-200 words)\", \"Medium (300-400 words)\", \"Long (500-700 words)\"])\n",
        "  start_ngrok = st.checkbox(\"Start ngrok tunnel\")\n",
        "  if start_ngrok:\n",
        "    if NGROK_AUTH_TOKEN:\n",
        "      ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "      url=ngrok.connect(8501)\n",
        "      st.success(f\"Public URL: {url}\")\n",
        "    else:\n",
        "      st.error(\"ngrok auth token not set in environment variables.\")\n",
        "\n",
        "uploaded_images = st.file_uploader(\"Upload multiple images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "\n",
        "#caption model\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "  processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  blip_model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  return processor, blip_model\n",
        "\n",
        "processor, blip_model = load_models()\n",
        "\n",
        "\n",
        "#config gemini\n",
        "if GEMINI_API_KEY:\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    @st.cache_resource\n",
        "    def load_gemini_model():\n",
        "      return genai.GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "\n",
        "    gemini_model=load_gemini_model()\n",
        "else:\n",
        "    st.error(\"GEMINI_API_KEY not set in environment variables.\")\n",
        "\n",
        "\n",
        "def get_captions(images):\n",
        "  captions=[]\n",
        "  for img in images:\n",
        "    if img.mode != \"RGB\":\n",
        "      img = img.convert(\"RGB\")\n",
        "    inputs=processor(images=img, return_tensors=\"pt\").to(blip_model.device)\n",
        "    out = blip_model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    captions.append(caption)\n",
        "  return captions\n",
        "\n",
        "def generated_story(captions, tone, length_label):\n",
        "  length_map = {\n",
        "      \"Short (100-200 words)\": (100, 200, 400),\n",
        "      \"Medium (300-400 words)\": (300, 400, 800),\n",
        "      \"Long (500-700 words)\": (500, 700, 1400)\n",
        "  }\n",
        "  min_words, max_words, max_tokens = length_map[length_label]\n",
        "\n",
        "  prompt = (\n",
        "      f\"You are a creative writer. Write a {tone.lower()} story based on the following image captions:\"\n",
        "      + \"\\n\".join([f\"- {cap}\" for cap in captions])\n",
        "      + f\" The story should be vivid, engaging, and emotionally rich, with a coherent beginning, middle and end.\"\n",
        "      + f\" Make it approximately between {min_words} and {max_words} words long.\"\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    response = gemini_model.generate_content(\n",
        "        contents=[prompt],\n",
        "        generation_config=genai.GenerationConfig(\n",
        "            temperature=0.9,\n",
        "            top_p=0.95,\n",
        "            max_output_tokens=max_tokens\n",
        "        )\n",
        "    )\n",
        "    # Check if the response contains candidates and if the finish reason is not 'SAFETY'\n",
        "    if response.candidates and response.candidates[0].finish_reason != 2: # Finish reason 2 typically indicates SAFETY\n",
        "        return response.text.strip()\n",
        "    else:\n",
        "        # Provide a more specific message if the response was blocked\n",
        "        return \"Story generation was blocked, possibly due to safety concerns with the content.\"\n",
        "\n",
        "  except Exception as e:\n",
        "      return f\"Error generating story: {e}\"\n",
        "\n",
        "#pdf generation\n",
        "def create_pdf(story_text, images):\n",
        "  buffer = io.BytesIO()\n",
        "  c = canvas.Canvas(buffer, pagesize=A4)\n",
        "  w, h = A4\n",
        "\n",
        "  try:\n",
        "          bg_img = Image.open(requests.get(BACKGROUND_IMAGE_URL, stream=True).raw).convert('RGB')\n",
        "          bg=ImageReader(bg_img)\n",
        "          c.drawImage(bg, 0, 0, width=w, height=h)\n",
        "  except:\n",
        "          pass\n",
        "\n",
        "  c.setFont(\"Helvetica-Bold\", 16)\n",
        "  c.drawString(50,h - 50, \"Generated Story\")\n",
        "\n",
        "  text = textwrap.wrap(story_text, width=100)\n",
        "  y = h - 80\n",
        "  for line in text:\n",
        "          if y < 80:\n",
        "            c.showPage()\n",
        "            y = h - 80\n",
        "          c.drawString(50, y, line)\n",
        "          y -= 15\n",
        "  if images:\n",
        "          c.showPage()\n",
        "          c.setFont(\"Helvetica-Bold\", 16)\n",
        "          c.drawString(50, h - 50, \"Uploaded Images\")\n",
        "          x, y = 50, h - 150\n",
        "          for img in images:\n",
        "              img.thumbnail((200, 200))\n",
        "              c.drawImage(ImageReader(img), x, y, width=200, height=200, preserveAspectRatio=True)\n",
        "              x += 220\n",
        "              if x > w - 50 - 200: # Adjusted condition to prevent image going out of bounds\n",
        "                  x = 50\n",
        "                  y -= 220\n",
        "                  if y < 80: # Check if new row would go off page\n",
        "                      c.showPage()\n",
        "                      y = h - 150\n",
        "                      x = 50 # Reset x for the new page\n",
        "          c.save()\n",
        "          buffer.seek(0)\n",
        "          return buffer\n",
        "\n",
        " # audio generation\n",
        "def create_audio(story):\n",
        "    audio_bytes = io.BytesIO()\n",
        "    tts = gTTS(text=story, lang=\"en\")\n",
        "    tts.write_to_fp(audio_bytes)\n",
        "    audio_bytes.seek(0)\n",
        "    return audio_bytes\n",
        "\n",
        "if st.button(\"Generate Story\", key=\"generate_story_button_1\") and uploaded_images:\n",
        "    if GEMINI_API_KEY: # Only proceed if API key is available\n",
        "        pil_images = [Image.open(img) for img in uploaded_images]\n",
        "        with st.spinner( \"Generating captions...\"):\n",
        "          captions = get_captions(pil_images)\n",
        "          for i, cap in enumerate(captions):\n",
        "              st.write(f\"{i+1}: {cap}\")\n",
        "        with st.spinner(\"Generating story...\"):\n",
        "          story = generated_story(captions, tone, length_label)\n",
        "          st.success(\"Story generated!\")\n",
        "          st.write(story)\n",
        "        with st.spinner(\"Creating PDF...\"):\n",
        "          pdf_file=create_pdf(story, pil_images)\n",
        "          st.download_button(\"Download Story as PDF\", data=pdf_file, file_name=\"generated_story.pdf\", mime=\"application/pdf\")\n",
        "        with st.spinner(\"Creating Audio...\"):\n",
        "          audio_file=create_audio(story)\n",
        "          st.download_button(\"Download Story as MP3\", data=audio_file, file_name=\"generated_story.mp3\", mime=\"audio/mp3\")\n",
        "    else:\n",
        "        st.error(\"Gemini API key is not set. Please set it in your environment variables.\")\n",
        "\n",
        "elif not uploaded_images and st.button(\"Generate Story\", key=\"generate_story_button_2\"): # Added condition to show warning only when button is clicked\n",
        "      st.warning(\"Upload at least one image to begin.\")"
      ],
      "metadata": {
        "id": "SNU3D0BuJpoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af909d11-44c7-4031-e7b9-5d967d34f5ce"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app_streamlit_story.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dbc22aa"
      },
      "source": [
        "!pip install -q streamlit pyngrok transformers torch gtts reportlab Pillow\n",
        "!streamlit run app_streamlit_story.py --server.port 8501 &>/content/log.txt &\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"33XlRRRqPXH9qe5tPEXfviVlTI6_477Si91yBwWMkY51w1vCx\")\n",
        "public_url=ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df07f65c"
      },
      "source": [
        "with open('/content/log.txt', 'r') as f:\n",
        "    print(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c867aa47"
      },
      "source": [
        "# Task\n",
        "Add background music to the MP3 output (via pydub) for creative flair."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7b00fc7"
      },
      "source": [
        "## Install necessary library\n",
        "\n",
        "### Subtask:\n",
        "Install pydub in the Colab environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3e8be08"
      },
      "source": [
        "**Rationale**:\n",
        "The subtask is to install the pydub library. I will use pip to install the package.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cd636a3"
      },
      "source": [
        "!pip install -q pydub"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d91b6ae"
      },
      "source": [
        "## Add background music\n",
        "\n",
        "### Subtask:\n",
        "Provide a way to include background music. This could be by uploading a music file or specifying a URL to a music file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "983f7cfa"
      },
      "source": [
        "**Rationale**:\n",
        "Add a file uploader in the Streamlit sidebar for background music and store the uploaded file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4aba0c8",
        "outputId": "33b1a17f-2b37-42f5-aca8-1cc30ce72fac"
      },
      "source": [
        "%%writefile app_streamlit_story.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import io, requests, os\n",
        "import textwrap\n",
        "from gtts import gTTS\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from google import genai\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.utils import ImageReader\n",
        "from pyngrok import ngrok\n",
        "from tempfile import NamedTemporaryFile\n",
        "import google.generativeai as genai\n",
        "import torch\n",
        "from pydub import AudioSegment\n",
        "\n",
        "#authentication\n",
        "NGROK_AUTH_TOKEN = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "BACKGROUND_IMAGE_URL= \"https://i.postimg.cc/t4BYWppf/Victoria-falls-1.jpg\"\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "#streamlit Page Setup\n",
        "st.set_page_config(page_title=\"StoryTeller\", layout=\"wide\")\n",
        "\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "    .stApp{{\n",
        "        background-image: url(\"{BACKGROUND_IMAGE_URL}\");\n",
        "        background-attachment: fixed;\n",
        "        background-size: cover;\n",
        "    }}\n",
        "    section[data-testid=\"stSidebar\"]{{\n",
        "        background:rgba(0,0,0,0.3);\n",
        "        background-filter:blur(10px);\n",
        "        border-radius:12px;\n",
        "        padding:10px;\n",
        "    }}\n",
        "    div[data-testid=\"stFileUploader\"]{{\n",
        "        background:rgba(255,255,255,0.2);\n",
        "        background-filter:blur(10px);\n",
        "        border-radius:12px;\n",
        "        padding:10px;\n",
        "    }}\n",
        "    html, body, h1, h2, h3, h4, h5, h6, p,div, span, label, li, input, textarea {{\n",
        "      color:#93A8AC !important;\n",
        "    }}\n",
        "    .stButton>button, .stDownloadButton>button {{\n",
        "      color:#93A8AC !important;\n",
        "      border-color:#93A8AC;\n",
        "    }}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.title(\"Multi-Image AI Storyteller\")\n",
        "st.markdown(\"Upload images - Generate story - Export as PDF & MP3\")\n",
        "\n",
        "with st.sidebar:\n",
        "  tone=st.selectbox(\"Tone\", [\"Descriptive\", \"Narrative\", \"Factual\", \"Simple\"])\n",
        "  length_label=st.selectbox(\"Length\", [\"Short (100-200 words)\", \"Medium (300-400 words)\", \"Long (500-700 words)\"])\n",
        "  uploaded_music = st.file_uploader(\"Upload Background Music\", type=[\"mp3\", \"wav\"])\n",
        "  start_ngrok = st.checkbox(\"Start ngrok tunnel\")\n",
        "  if start_ngrok:\n",
        "    if NGROK_AUTH_TOKEN:\n",
        "      ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "      url=ngrok.connect(8501)\n",
        "      st.success(f\"Public URL: {url}\")\n",
        "    else:\n",
        "      st.error(\"ngrok auth token not set in environment variables.\")\n",
        "\n",
        "uploaded_images = st.file_uploader(\"Upload multiple images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "\n",
        "#caption model\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "  processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  blip_model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  return processor, blip_model\n",
        "\n",
        "processor, blip_model = load_models()\n",
        "\n",
        "\n",
        "#config gemini\n",
        "if GEMINI_API_KEY:\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    @st.cache_resource\n",
        "    def load_gemini_model():\n",
        "      return genai.GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "\n",
        "    gemini_model=load_gemini_model()\n",
        "else:\n",
        "    st.error(\"GEMINI_API_KEY not set in environment variables.\")\n",
        "\n",
        "\n",
        "def get_captions(images):\n",
        "  captions=[]\n",
        "  for img in images:\n",
        "    if img.mode != \"RGB\":\n",
        "      img = img.convert(\"RGB\")\n",
        "    inputs=processor(images=img, return_tensors=\"pt\").to(blip_model.device)\n",
        "    out = blip_model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    captions.append(caption)\n",
        "  return captions\n",
        "\n",
        "def generated_story(captions, tone, length_label):\n",
        "  length_map = {\n",
        "      \"Short (100-200 words)\": (100, 200, 400),\n",
        "      \"Medium (300-400 words)\": (300, 400, 800),\n",
        "      \"Long (500-700 words)\": (500, 700, 1400)\n",
        "  }\n",
        "  min_words, max_words, max_tokens = length_map[length_label]\n",
        "\n",
        "  prompt = (\n",
        "      f\"You are a creative writer. Write a {tone.lower()} story based on the following image captions:\"\n",
        "      + \"\\n\".join([f\"- {cap}\" for cap in captions])\n",
        "      + f\" The story should be vivid, engaging, and emotionally rich, with a coherent beginning, middle and end.\"\n",
        "      + f\" Make it approximately between {min_words} and {max_words} words long.\"\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    response = gemini_model.generate_content(\n",
        "        contents=[prompt],\n",
        "        generation_config=genai.GenerationConfig(\n",
        "            temperature=0.9,\n",
        "            top_p=0.95,\n",
        "            max_output_tokens=max_tokens\n",
        "        )\n",
        "    )\n",
        "    # Check if the response contains candidates and if the finish reason is not 'SAFETY'\n",
        "    if response.candidates and response.candidates[0].finish_reason != 2: # Finish reason 2 typically indicates SAFETY\n",
        "        return response.text.strip()\n",
        "    else:\n",
        "        # Provide a more specific message if the response was blocked\n",
        "        return \"Story generation was blocked, possibly due to safety concerns with the content.\"\n",
        "\n",
        "  except Exception as e:\n",
        "      return f\"Error generating story: {e}\"\n",
        "\n",
        "#pdf generation\n",
        "def create_pdf(story_text, images):\n",
        "  buffer = io.BytesIO()\n",
        "  c = canvas.Canvas(buffer, pagesize=A4)\n",
        "  w, h = A4\n",
        "\n",
        "  try:\n",
        "          bg_img = Image.open(requests.get(BACKGROUND_IMAGE_URL, stream=True).raw).convert('RGB')\n",
        "          bg=ImageReader(bg_img)\n",
        "          c.drawImage(bg, 0, 0, width=w, height=h)\n",
        "  except:\n",
        "          pass\n",
        "\n",
        "  c.setFont(\"Helvetica-Bold\", 16)\n",
        "  c.drawString(50,h - 50, \"Generated Story\")\n",
        "\n",
        "  text = textwrap.wrap(story_text, width=100)\n",
        "  y = h - 80\n",
        "  for line in text:\n",
        "          if y < 80:\n",
        "            c.showPage()\n",
        "            y = h - 80\n",
        "          c.drawString(50, y, line)\n",
        "          y -= 15\n",
        "  if images:\n",
        "          c.showPage()\n",
        "          c.setFont(\"Helvetica-Bold\", 16)\n",
        "          c.drawString(50, h - 50, \"Uploaded Images\")\n",
        "          x, y = 50, h - 150\n",
        "          for img in images:\n",
        "              img.thumbnail((200, 200))\n",
        "              c.drawImage(ImageReader(img), x, y, width=200, height=200, preserveAspectRatio=True)\n",
        "              x += 220\n",
        "              if x > w - 50 - 200: # Adjusted condition to prevent image going out of bounds\n",
        "                  x = 50\n",
        "                  y -= 220\n",
        "                  if y < 80: # Check if new row would go off page\n",
        "                      c.showPage()\n",
        "                      y = h - 150\n",
        "                      x = 50 # Reset x for the new page\n",
        "          c.save()\n",
        "          buffer.seek(0)\n",
        "          return buffer\n",
        "\n",
        " # audio generation\n",
        "def create_audio(story, background_music=None):\n",
        "    audio_bytes = io.BytesIO()\n",
        "    tts = gTTS(text=story, lang=\"en\")\n",
        "    tts.write_to_fp(audio_bytes)\n",
        "    audio_bytes.seek(0)\n",
        "\n",
        "    if background_music:\n",
        "        try:\n",
        "            story_audio = AudioSegment.from_file(audio_bytes, format=\"mp3\")\n",
        "            background_audio = AudioSegment.from_file(io.BytesIO(background_music.getvalue()), format=background_music.type.split('/')[-1])\n",
        "\n",
        "            # Ensure background music is at least as long as the story audio\n",
        "            if len(background_audio) < len(story_audio):\n",
        "                background_audio = background_audio * (len(story_audio) // len(background_audio) + 1)\n",
        "\n",
        "            # Overlay background music (adjust volume as needed)\n",
        "            combined_audio = story_audio.overlay(background_audio[:len(story_audio)] - 15) # -15dB for background\n",
        "\n",
        "            combined_audio_bytes = io.BytesIO()\n",
        "            combined_audio.export(combined_audio_bytes, format=\"mp3\")\n",
        "            combined_audio_bytes.seek(0)\n",
        "            return combined_audio_bytes\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Could not add background music: {e}\")\n",
        "            return audio_bytes # Return story audio only if background music fails\n",
        "    else:\n",
        "        return audio_bytes\n",
        "\n",
        "if st.button(\"Generate Story\", key=\"generate_story_button_1\") and uploaded_images:\n",
        "    if GEMINI_API_KEY: # Only proceed if API key is available\n",
        "        pil_images = [Image.open(img) for img in uploaded_images]\n",
        "        with st.spinner( \"Generating captions...\"):\n",
        "          captions = get_captions(pil_images)\n",
        "          for i, cap in enumerate(captions):\n",
        "              st.write(f\"{i+1}: {cap}\")\n",
        "        with st.spinner(\"Generating story...\"):\n",
        "          story = generated_story(captions, tone, length_label)\n",
        "          st.success(\"Story generated!\")\n",
        "          st.write(story)\n",
        "        with st.spinner(\"Creating PDF...\"):\n",
        "          pdf_file=create_pdf(story, pil_images)\n",
        "          st.download_button(\"Download Story as PDF\", data=pdf_file, file_name=\"generated_story.pdf\", mime=\"application/pdf\")\n",
        "        with st.spinner(\"Creating Audio...\"):\n",
        "          audio_file=create_audio(story, uploaded_music)\n",
        "          st.download_button(\"Download Story as MP3\", data=audio_file, file_name=\"generated_story.mp3\", mime=\"audio/mp3\")\n",
        "    else:\n",
        "        st.error(\"Gemini API key is not set. Please set it in your environment variables.\")\n",
        "\n",
        "elif not uploaded_images and st.button(\"Generate Story\", key=\"generate_story_button_2\"): # Added condition to show warning only when button is clicked\n",
        "      st.warning(\"Upload at least one image to begin.\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app_streamlit_story.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9903ca8a"
      },
      "source": [
        "## Update streamlit app\n",
        "\n",
        "### Subtask:\n",
        "Regenerate the app_streamlit_story.py file with the modified create_audio function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be526284"
      },
      "source": [
        "**Rationale**:\n",
        "Write the updated app_streamlit_story.py file with the modified create_audio function that handles background music.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17ca9cb8",
        "outputId": "698b20d4-a8bf-4762-a1be-c800fffef2f6"
      },
      "source": [
        "%%writefile app_streamlit_story.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import io, requests, os\n",
        "import textwrap\n",
        "from gtts import gTTS\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from google import genai\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.utils import ImageReader\n",
        "from pyngrok import ngrok\n",
        "from tempfile import NamedTemporaryFile\n",
        "import google.generativeai as genai\n",
        "import torch\n",
        "from pydub import AudioSegment\n",
        "\n",
        "#authentication\n",
        "NGROK_AUTH_TOKEN = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "BACKGROUND_IMAGE_URL= \"https://i.postimg.cc/t4BYWppf/Victoria-falls-1.jpg\"\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "#streamlit Page Setup\n",
        "st.set_page_config(page_title=\"StoryTeller\", layout=\"wide\")\n",
        "\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "    .stApp{{\n",
        "        background-image: url(\"{BACKGROUND_IMAGE_URL}\");\n",
        "        background-attachment: fixed;\n",
        "        background-size: cover;\n",
        "    }}\n",
        "    section[data-testid=\"stSidebar\"]{{\n",
        "        background:rgba(0,0,0,0.3);\n",
        "        background-filter:blur(10px);\n",
        "        border-radius:12px;\n",
        "        padding:10px;\n",
        "    }}\n",
        "    div[data-testid=\"stFileUploader\"]{{\n",
        "        background:rgba(255,255,255,0.2);\n",
        "        background-filter:blur(10px);\n",
        "        border-radius:12px;\n",
        "        padding:10px;\n",
        "    }}\n",
        "    html, body, h1, h2, h3, h4, h5, h6, p,div, span, label, li, input, textarea {{\n",
        "      color:#93A8AC !important;\n",
        "    }}\n",
        "    .stButton>button, .stDownloadButton>button {{\n",
        "      color:#93A8AC !important;\n",
        "      border-color:#93A8AC;\n",
        "    }}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.title(\"Multi-Image AI Storyteller\")\n",
        "st.markdown(\"Upload images - Generate story - Export as PDF & MP3\")\n",
        "\n",
        "with st.sidebar:\n",
        "  tone=st.selectbox(\"Tone\", [\"Descriptive\", \"Narrative\", \"Factual\", \"Simple\"])\n",
        "  length_label=st.selectbox(\"Length\", [\"Short (100-200 words)\", \"Medium (300-400 words)\", \"Long (500-700 words)\"])\n",
        "  uploaded_music = st.file_uploader(\"Upload Background Music\", type=[\"mp3\", \"wav\"])\n",
        "  start_ngrok = st.checkbox(\"Start ngrok tunnel\")\n",
        "  if start_ngrok:\n",
        "    if NGROK_AUTH_TOKEN:\n",
        "      ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "      url=ngrok.connect(8501)\n",
        "      st.success(f\"Public URL: {url}\")\n",
        "    else:\n",
        "      st.error(\"ngrok auth token not set in environment variables.\")\n",
        "\n",
        "uploaded_images = st.file_uploader(\"Upload multiple images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "\n",
        "#caption model\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "  processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  blip_model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  return processor, blip_model\n",
        "\n",
        "processor, blip_model = load_models()\n",
        "\n",
        "\n",
        "#config gemini\n",
        "if GEMINI_API_KEY:\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    @st.cache_resource\n",
        "    def load_gemini_model():\n",
        "      return genai.GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "\n",
        "    gemini_model=load_gemini_model()\n",
        "else:\n",
        "    st.error(\"GEMINI_API_KEY not set in environment variables.\")\n",
        "\n",
        "\n",
        "def get_captions(images):\n",
        "  captions=[]\n",
        "  for img in images:\n",
        "    if img.mode != \"RGB\":\n",
        "      img = img.convert(\"RGB\")\n",
        "    inputs=processor(images=img, return_tensors=\"pt\").to(blip_model.device)\n",
        "    out = blip_model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    captions.append(caption)\n",
        "  return captions\n",
        "\n",
        "def generated_story(captions, tone, length_label):\n",
        "  length_map = {\n",
        "      \"Short (100-200 words)\": (100, 200, 400),\n",
        "      \"Medium (300-400 words)\": (300, 400, 800),\n",
        "      \"Long (500-700 words)\": (500, 700, 1400)\n",
        "  }\n",
        "  min_words, max_words, max_tokens = length_map[length_label]\n",
        "\n",
        "  prompt = (\n",
        "      f\"You are a creative writer. Write a {tone.lower()} story based on the following image captions:\"\n",
        "      + \"\\n\".join([f\"- {cap}\" for cap in captions])\n",
        "      + f\" The story should be vivid, engaging, and emotionally rich, with a coherent beginning, middle and end.\"\n",
        "      + f\" Make it approximately between {min_words} and {max_words} words long.\"\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    response = gemini_model.generate_content(\n",
        "        contents=[prompt],\n",
        "        generation_config=genai.GenerationConfig(\n",
        "            temperature=0.9,\n",
        "            top_p=0.95,\n",
        "            max_output_tokens=max_tokens\n",
        "        )\n",
        "    )\n",
        "    # Check if the response contains candidates and if the finish reason is not 'SAFETY'\n",
        "    if response.candidates and response.candidates[0].finish_reason != 2: # Finish reason 2 typically indicates SAFETY\n",
        "        return response.text.strip()\n",
        "    else:\n",
        "        # Provide a more specific message if the response was blocked\n",
        "        return \"Story generation was blocked, possibly due to safety concerns with the content.\"\n",
        "\n",
        "  except Exception as e:\n",
        "      return f\"Error generating story: {e}\"\n",
        "\n",
        "#pdf generation\n",
        "def create_pdf(story_text, images):\n",
        "  buffer = io.BytesIO()\n",
        "  c = canvas.Canvas(buffer, pagesize=A4)\n",
        "  w, h = A4\n",
        "\n",
        "  try:\n",
        "          bg_img = Image.open(requests.get(BACKGROUND_IMAGE_URL, stream=True).raw).convert('RGB')\n",
        "          bg=ImageReader(bg_img)\n",
        "          c.drawImage(bg, 0, 0, width=w, height=h)\n",
        "  except:\n",
        "          pass\n",
        "\n",
        "  c.setFont(\"Helvetica-Bold\", 16)\n",
        "  c.drawString(50,h - 50, \"Generated Story\")\n",
        "\n",
        "  text = textwrap.wrap(story_text, width=100)\n",
        "  y = h - 80\n",
        "  for line in text:\n",
        "          if y < 80:\n",
        "            c.showPage()\n",
        "            y = h - 80\n",
        "          c.drawString(50, y, line)\n",
        "          y -= 15\n",
        "  if images:\n",
        "          c.showPage()\n",
        "          c.setFont(\"Helvetica-Bold\", 16)\n",
        "          c.drawString(50, h - 50, \"Uploaded Images\")\n",
        "          x, y = 50, h - 150\n",
        "          for img in images:\n",
        "              img.thumbnail((200, 200))\n",
        "              c.drawImage(ImageReader(img), x, y, width=200, height=200, preserveAspectRatio=True)\n",
        "              x += 220\n",
        "              if x > w - 50 - 200: # Adjusted condition to prevent image going out of bounds\n",
        "                  x = 50\n",
        "                  y -= 220\n",
        "                  if y < 80: # Check if new row would go off page\n",
        "                      c.showPage()\n",
        "                      y = h - 150\n",
        "                      x = 50 # Reset x for the new page\n",
        "          c.save()\n",
        "          buffer.seek(0)\n",
        "          return buffer\n",
        "\n",
        " # audio generation\n",
        "def create_audio(story, background_music=None):\n",
        "    audio_bytes = io.BytesIO()\n",
        "    tts = gTTS(text=story, lang=\"en\")\n",
        "    tts.write_to_fp(audio_bytes)\n",
        "    audio_bytes.seek(0)\n",
        "\n",
        "    if background_music:\n",
        "        try:\n",
        "            story_audio = AudioSegment.from_file(audio_bytes, format=\"mp3\")\n",
        "            background_audio = AudioSegment.from_file(io.BytesIO(background_music.getvalue()), format=background_music.type.split('/')[-1])\n",
        "\n",
        "            # Ensure background music is at least as long as the story audio\n",
        "            if len(background_audio) < len(story_audio):\n",
        "                background_audio = background_audio * (len(story_audio) // len(background_audio) + 1)\n",
        "\n",
        "            # Overlay background music (adjust volume as needed)\n",
        "            combined_audio = story_audio.overlay(background_audio[:len(story_audio)] - 15) # -15dB for background\n",
        "\n",
        "            combined_audio_bytes = io.BytesIO()\n",
        "            combined_audio.export(combined_audio_bytes, format=\"mp3\")\n",
        "            combined_audio_bytes.seek(0)\n",
        "            return combined_audio_bytes\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Could not add background music: {e}\")\n",
        "            return audio_bytes # Return story audio only if background music fails\n",
        "    else:\n",
        "        return audio_bytes\n",
        "\n",
        "if st.button(\"Generate Story\", key=\"generate_story_button_1\") and uploaded_images:\n",
        "    if GEMINI_API_KEY: # Only proceed if API key is available\n",
        "        pil_images = [Image.open(img) for img in uploaded_images]\n",
        "        with st.spinner( \"Generating captions...\"):\n",
        "          captions = get_captions(pil_images)\n",
        "          for i, cap in enumerate(captions):\n",
        "              st.write(f\"{i+1}: {cap}\")\n",
        "        with st.spinner(\"Generating story...\"):\n",
        "          story = generated_story(captions, tone, length_label)\n",
        "          st.success(\"Story generated!\")\n",
        "          st.write(story)\n",
        "        with st.spinner(\"Creating PDF...\"):\n",
        "          pdf_file=create_pdf(story, pil_images)\n",
        "          st.download_button(\"Download Story as PDF\", data=pdf_file, file_name=\"generated_story.pdf\", mime=\"application/pdf\")\n",
        "        with st.spinner(\"Creating Audio...\"):\n",
        "          audio_file=create_audio(story, uploaded_music)\n",
        "          st.download_button(\"Download Story as MP3\", data=audio_file, file_name=\"generated_story.mp3\", mime=\"audio/mp3\")\n",
        "    else:\n",
        "        st.error(\"Gemini API key is not set. Please set it in your environment variables.\")\n",
        "\n",
        "elif not uploaded_images and st.button(\"Generate Story\", key=\"generate_story_button_2\"): # Added condition to show warning only when button is clicked\n",
        "      st.warning(\"Upload at least one image to begin.\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app_streamlit_story.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dd087da"
      },
      "source": [
        "## Run streamlit app\n",
        "\n",
        "### Subtask:\n",
        "Execute the cell to run the Streamlit application with the new functionality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51c14437"
      },
      "source": [
        "**Rationale**:\n",
        "Execute the code cell to run the Streamlit application and generate the public URL.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "031afe48",
        "outputId": "8a575d75-22fb-4693-c2c1-fe542c0713aa"
      },
      "source": [
        "!pip install -q streamlit pyngrok transformers torch gtts reportlab Pillow\n",
        "!streamlit run app_streamlit_story.py --server.port 8501 &>/content/log.txt &\n",
        "\n",
        "from pyngrok import ngrok\n",
        "# ngrok token is hardcoded here for demonstration purpose, this should be stored as a secret.\n",
        "ngrok.set_auth_token(\"33XlRRRqPXH9qe5tPEXfviVlTI6_477Si91yBwWMkY51w1vCx\")\n",
        "public_url=ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Public URL: NgrokTunnel: \"https://forespent-bullishly-saran.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvJeDlweQCWhuaZwifhoTn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}