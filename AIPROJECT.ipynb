{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Irene32Mwaniki/AI-Storytelling-Project-/blob/main/AIPROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f21d4a19"
      },
      "source": [
        "import os\n",
        "\n",
        "# Read the API key from the environment variable\n",
        "if \"GEMINI_API_KEY\" in os.environ:\n",
        "    GEMINI_API_KEY = os.environ['GEMINI_API_KEY']\n",
        "    print(\"API key loaded from environment variable.\")\n",
        "else:\n",
        "    print(\"Error: GEMINI_API_KEY environment variable not set.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVnjw_PGcw42"
      },
      "source": [
        "Install the packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MfQ7HwlcXBi"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers pillow google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9Yj0KcxcXTo"
      },
      "outputs": [],
      "source": [
        "from google import generativeai as genai\n",
        "import os\n",
        "#client=genai.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEc8xszscXcO"
      },
      "outputs": [],
      "source": [
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "  print(\"Please set your Gemini API key in the environment variable GEMINI_API_KEY\")\n",
        "else:\n",
        "  genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
        "  MODEL=\"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2QXrW8phG7X"
      },
      "outputs": [],
      "source": [
        "prompt=input(\"Enter your Story prompt and press enter:\\n\")\n",
        "if prompt.strip()==\"\":\n",
        "  print(\"No prompt entered, Exiting.\")\n",
        "else:\n",
        "    print(f\"Generating story for prompt: {prompt}\")\n",
        "    print(\"It may take a few seconds\")\n",
        "    try:\n",
        "      model = genai.GenerativeModel(model_name=MODEL)\n",
        "      resp=model.generate_content(contents=[prompt])\n",
        "      print(\"\\n----Generated Story----\\n\")\n",
        "      print(resp.text)\n",
        "    except Exception as e:\n",
        "      print(f\"Error generating story: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiT_p31RvhJp"
      },
      "source": [
        "Day 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTL4D_5Sucai"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers pillow google-generativeai timm # pytorch image package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiIuPAL-ucMn"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "import os\n",
        "from google import genai\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-apDd0UpvjzW"
      },
      "outputs": [],
      "source": [
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "  print(\"Please set your Gemini API key in the environment variable GEMINI_API_KEY\")\n",
        "else:\n",
        "  from google import generativeai as genai\n",
        "  genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
        "  MODEL=\"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1kiZe6SxT1b"
      },
      "outputs": [],
      "source": [
        "processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDnshHgPx_Pw"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  images=Image.open(fn).convert('RGB')\n",
        "  display(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8pvmKpgzkuP"
      },
      "outputs": [],
      "source": [
        "for fn in uploaded.keys():\n",
        "    images = Image.open(fn).convert('RGB')\n",
        "    inputs = processor(images=images, return_tensors=\"pt\")\n",
        "    out = model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"Caption generated by BLIP for {fn}:\")\n",
        "    print(caption)\n",
        "    print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKuwa3l51XDy"
      },
      "outputs": [],
      "source": [
        "story_prompt=(f\"Write a short story (around 300 words) based on this scene description: {caption}\")\n",
        "print(story_prompt)\n",
        "\n",
        "print(\"Sending this to Gemini. \\n\")\n",
        "\n",
        "try:\n",
        "  model = genai.GenerativeModel(model_name=MODEL)\n",
        "  response=model.generate_content(contents=[story_prompt])\n",
        "  story=response.text\n",
        "  print(\"\\n-----Generated Story -----\\n\")\n",
        "  print(story)\n",
        "except Exception as e:\n",
        "  print(f\"Error generating story: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kibvmEzS4JpM"
      },
      "outputs": [],
      "source": [
        "with open(\"generated_story.txt\", \"w\") as f:\n",
        "  f.write(story)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"generated_story.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ5vXGvA6B52"
      },
      "outputs": [],
      "source": [
        "Day 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpfF8_u0qy62"
      },
      "outputs": [],
      "source": [
        "!pip install -q ipywidgets google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH4cQUL9qyyM"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "images=[]\n",
        "image_names=[]\n",
        "\n",
        "for name, file in uploaded.items():\n",
        "  image=Image.open(io.BytesIO(file)).convert('RGB')\n",
        "  image_names.append(name)\n",
        "  images.append(image)\n",
        "  display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-2HD0_cBO3U"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "import os\n",
        "from google import genai\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkBe9QAztrVk"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "from google import generativeai as genai\n",
        "\n",
        "processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "blip_model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "\n",
        "captions=[]\n",
        "\n",
        "for img in images:\n",
        "  inputs=processor(images=img,return_tensors='pt')\n",
        "  out=blip_model.generate(**inputs, max_new_tokens=30)\n",
        "  caption=processor.decode(out[0],skip_special_tokens=True)\n",
        "  captions.append(caption)\n",
        "\n",
        "\n",
        "  print(\"Captions generates from images:\")\n",
        "  for i, caption in enumerate(captions):\n",
        "    print(f\"{image_names[i]}: {caption}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI_H3NINtrPn"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display , clear_output\n",
        "\n",
        "\n",
        "tone_dropdown=widgets.Dropdown(\n",
        "    options=[\"Mystery\", \"Sci-fi\", \"Horror\", \"Adventorous\", \"Romantic\"],\n",
        "    value=\"Sci-fi\",\n",
        "    description=\"Tone:\"\n",
        ")\n",
        "\n",
        "length_dropdown=widgets.Dropdown(\n",
        "    options=[\"Short(100-200 words)\", \"Medium(300-400 words)\", \"Long(500-700 words)\"],\n",
        "    value=\"Medium(300-400 words)\",\n",
        "    description=\"Length:\"\n",
        ")\n",
        "\n",
        "generate_button=widgets.Button(description=\"Generate Story\")\n",
        "output_area=widgets.Output()\n",
        "\n",
        "display(tone_dropdown, length_dropdown, generate_button, output_area)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-37M75Pi2BP9"
      },
      "outputs": [],
      "source": [
        "def on_generate_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        selected_tone = tone_dropdown.value\n",
        "        length_map = {\n",
        "            \"Short(100-200 words)\": \"100-200 words\",\n",
        "            \"Medium(300-400 words)\": \"300 - 400 words\",\n",
        "            \"Long(500-700 words)\": \"500 - 700 words\"\n",
        "        }\n",
        "        length = length_map[length_dropdown.value]\n",
        "\n",
        "        # Define MODEL here to ensure it's accessible\n",
        "        MODEL=\"gemini-2.5-flash\"\n",
        "\n",
        "        caption_prompt = \"\\n\".join([f\"-{c}\" for c in captions])\n",
        "\n",
        "        outline_prompt = (\n",
        "            f\"Using the following scene descriptions, create a 4-chapter story outline. \"\n",
        "            f\"Each chapter should have a title and a short summary.\\n\\n\"\n",
        "            f\"{caption_prompt}\\n\\nOutline:\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            model = genai.GenerativeModel(model_name=MODEL)\n",
        "            outline_response = model.generate_content(contents=[outline_prompt])\n",
        "            outline_text = outline_response.text\n",
        "            print(\" Story Outline:\\n\")\n",
        "            print(outline_text)\n",
        "\n",
        "            full_story = \"\"\n",
        "            for i in range(1, 5):  # Assuming 4 chapters based on the outline prompt\n",
        "                chapter_prompt = (\n",
        "                    f\"Using the outline below, write Chapter {i} in a {selected_tone} tone. \"\n",
        "                    f\"Make it {length}. Add vivid details, good pacing, and consistent characters.\\n\\n\"\n",
        "                    f\"{outline_text}\\n\\nChapter {i}:\"\n",
        "                )\n",
        "                chapter_response = model.generate_content(contents=[chapter_prompt])\n",
        "                chapter_text = chapter_response.text\n",
        "                print(f\"\\n Chapter {i}: \\n\")\n",
        "                print(chapter_text)\n",
        "                full_story += f\"\\n\\nChapter {i}: \\n{chapter_text}\"\n",
        "\n",
        "            with open(\"multi_image_story.txt\", \"w\") as f:\n",
        "                f.write(full_story)\n",
        "            print(\"\\nStory saved as multi_image_story.txt\")\n",
        "\n",
        "            from google.colab import files\n",
        "            files.download(\"multi_image_story.txt\")\n",
        "        except Exception as e:\n",
        "            print(\"Error generating story: \", e)\n",
        "\n",
        "generate_button.on_click(on_generate_button_clicked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOju_owg2BJv"
      },
      "outputs": [],
      "source": [
        "Day 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gtts reportlab"
      ],
      "metadata": {
        "id": "e7PwUayuT-PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_text = \"\"\"\n",
        "**Chapter 1: The Muddy Promise**\n",
        "*   **Summary:** Lily and Daisy, two inseparable friends, spend their days in joyful abandon, their laughter echoing across the field as they create elaborate mud castles. Nearby, Old Mr. Silas sits peacefully with his loyal dog, Buster, a quiet fixture in their daily lives. The girls often overhear snippets of village tales about the \"Whispering Falls\" and the mysteries hidden beyond the familiar path, sparking a shared dream of adventure that begins to overshadow their muddy play.\n",
        "\n",
        "**Chapter 2: A Glimmer of the Falls**\n",
        "*   **Summary:** Driven by their growing curiosity, Lily and Daisy decide to finally seek out the legendary Whispering Falls. They bid farewell to their usual play spot, packing a small satchel with provisions. As they venture further than ever before, they pass Mr. Silas and Buster once more. Mr. Silas, sensing their budding quest, offers a knowing smile and a cryptic word of encouragement about listening to the land. The girls follow a winding, overgrown track, their excitement building until they catch their first breathtaking glimpse of the majestic waterfall, its cascades framing a unique road carved straight through its base.\n",
        "\n",
        "**Chapter 3: The Veiled Passage**\n",
        "*   **Summary:** Standing before the powerful Whispering Falls, Lily and Daisy are awestruck by its beauty and the strange duality of the ancient water meeting the man-made road. They bravely traverse the damp, echoing passage of the road through the falls, feeling as though they are crossing a threshold into another realm. Emerging on the other side, the air feels different, the forest denser and more wild. They realize the waterfall was not an endpoint, but a gateway to a deeper, more untamed part of the world, where their true adventure begins.\n",
        "\n",
        "**Chapter 4: The Forest's Secret Keeper**\n",
        "*   **Summary:** Deeper into the ancient forest, sunlight filters through the dense canopy, dappling the mossy ground. Lily and Daisy, their senses alive with the sights and sounds of the wild, follow the rustling leaves and distant calls. Their journey culminates in a hidden clearing where, hanging playfully from a high tree branch, a curious monkey observes them with intelligent, ancient eyes. The monkey seems to be a silent guardian, a symbol of the forest's untamed spirit. The girls understand that the true \"secret\" isn't something to find, but the profound connection to nature they've experienced, leaving the forest forever changed by its wild magic.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fiDFn2MUT-Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "from gtts import gTTS\n",
        "\n",
        "\n",
        "def export_pdf(text,filename=\"story_text\"):\n",
        "  c=canvas.Canvas(f\"{filename}.pdf\",pagesize=letter)\n",
        "  width, height=letter\n",
        "  text_object=c.beginText(40,height-40)\n",
        "  text_object.setFont(\"Helvetica\",12)\n",
        "\n",
        "  for line in text.split('\\n'):\n",
        "    for subline in [line[i:i+90] for i in range(0,len(line),90)]:\n",
        "      text_object.textLine(subline)\n",
        "  c.drawText(text_object)\n",
        "  c.showPage()\n",
        "  c.save()\n",
        "\n",
        "export_pdf(story_text)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"story_text.pdf\")"
      ],
      "metadata": {
        "id": "d0kq9rUWWjxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "\n",
        "voices = {\n",
        "    \"Default English (US Female)\": {\"lang\": \"en\", \"gender\": \"female\", \"accent\": \"us\"},\n",
        "    \"Default English (US Male)\": {\"lang\": \"en\", \"gender\": \"male\", \"accent\": \"us\"},\n",
        "    \"British Accent\": { \"lang\": \"en\", \"tld\": \"co.uk\"},\n",
        "    \"Australian Accnet\": { \"lang\": \"en\", \"tld\": \"com.au\"},\n",
        "    \"Indian Accent\": { \"lang\": \"en\", \"tld\": \"co.in\"},\n",
        "    \"French Accent\": { \"lang\": \"fr\", \"tld\": \"fr\"},\n",
        "    \"Spanish Accent\": { \"lang\": \"es\", \"tld\": \"es\"},\n",
        "    \"German Accent\": { \"lang\": \"de\", \"tld\": \"de\"},\n",
        "    \"Italian Accent\": { \"lang\": \"it\", \"tld\": \"it\"},\n",
        "    \"Japanese Accent\": { \"lang\": \"ja\", \"tld\": \"jp\"},\n",
        "    \"Slow Reading Voice\": { \"lang\": \"en\", \"slow\": True}\n",
        "}\n",
        "\n",
        "for label,options in voices.items():\n",
        "  print(f\"Generating Audio: {label}\")\n",
        "\n",
        "  tts=gTTS(\n",
        "      text=story_text,\n",
        "      lang=options[\"lang\"],\n",
        "      tld=options.get(\"tld\", \"com\"),\n",
        "      slow=options.get(\"slow\", False)\n",
        "  )\n",
        "\n",
        "  filename=f\"{label.replace(' ', '_').lower()}.mp3\"\n",
        "\n",
        "  tts.save(filename)\n",
        "\n",
        "  display(Audio(filename=filename, autoplay=False))\n",
        "\n",
        "  files.download(filename)"
      ],
      "metadata": {
        "id": "0hJwiLnkWjm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Day 5"
      ],
      "metadata": {
        "id": "7FjBnbMPj9Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_streamlit_story.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import io, requests, os\n",
        "import textwrap\n",
        "from gtts import gTTS\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from google import genai\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.utils import ImageReader\n",
        "from pyngrok import ngrok\n",
        "from tempfile import NamedTemporaryFile\n",
        "import google.generativeai as genai\n",
        "import torch\n",
        "\n",
        "#authentication\n",
        "NGROK_AUTH_TOKEN = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "BACKGROUND_IMAGE_URL= \"https://i.postimg.cc/t4BYWppf/Victoria-falls-1.jpg\"\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "#streamlit Page Setup\n",
        "st.set_page_config(page_title=\"StoryTeller\", layout=\"wide\")\n",
        "\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "    .stApp{{\n",
        "        background-image: url(\"{BACKGROUND_IMAGE_URL}\");\n",
        "        background-attachment: fixed;\n",
        "        background-size: cover;\n",
        "    }}\n",
        "    section[data-testid=\"stSidebar\"]{{\n",
        "        background:rgba(0,0,0,0.3);\n",
        "        background-filter:blur(10px);\n",
        "        border-radius:12px;\n",
        "        padding:10px;\n",
        "    }}\n",
        "    div[data-testid=\"stFileUploader\"]{{\n",
        "        background:rgba(255,255,255,0.2);\n",
        "        background-filter:blur(10px);\n",
        "        border-radius:12px;\n",
        "        padding:10px;\n",
        "    }}\n",
        "    html, body, h1, h2, h3, h4, h5, h6, p,div, span, label, li, input, textarea {{\n",
        "      color:#93A8AC !important;\n",
        "    }}\n",
        "    .stButton>button, .stDownloadButton>button {{\n",
        "      color:#93A8AC !important;\n",
        "      border-color:#93A8AC;\n",
        "    }}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.title(\"Multi-Image AI Storyteller\")\n",
        "st.markdown(\"Upload images - Generate story - Export as PDF & MP3\")\n",
        "\n",
        "with st.sidebar:\n",
        "  tone=st.selectbox(\"Tone\", [\"Descriptive\", \"Narrative\", \"Factual\", \"Simple\"])\n",
        "  length_label=st.selectbox(\"Length\", [\"Short (100-200 words)\", \"Medium (300-400 words)\", \"Long (500-700 words)\"])\n",
        "  start_ngrok = st.checkbox(\"Start ngrok tunnel\")\n",
        "  if start_ngrok:\n",
        "    if NGROK_AUTH_TOKEN:\n",
        "      ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "      url=ngrok.connect(8501)\n",
        "      st.success(f\"Public URL: {url}\")\n",
        "    else:\n",
        "      st.error(\"ngrok auth token not set in environment variables.\")\n",
        "\n",
        "uploaded_images = st.file_uploader(\"Upload multiple images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "\n",
        "#caption model\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "  processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  blip_model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "  return processor, blip_model\n",
        "\n",
        "processor, blip_model = load_models()\n",
        "\n",
        "\n",
        "#config gemini\n",
        "if GEMINI_API_KEY:\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    @st.cache_resource\n",
        "    def load_gemini_model():\n",
        "      return genai.GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "\n",
        "    gemini_model=load_gemini_model()\n",
        "else:\n",
        "    st.error(\"GEMINI_API_KEY not set in environment variables.\")\n",
        "\n",
        "\n",
        "def get_captions(images):\n",
        "  captions=[]\n",
        "  for img in images:\n",
        "    if img.mode != \"RGB\":\n",
        "      img = img.convert(\"RGB\")\n",
        "    inputs=processor(images=img, return_tensors=\"pt\").to(blip_model.device)\n",
        "    out = blip_model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    captions.append(caption)\n",
        "  return captions\n",
        "\n",
        "def generated_story(captions, tone, length_label):\n",
        "  length_map = {\n",
        "      \"Short (100-200 words)\": (100, 200, 400),\n",
        "      \"Medium (300-400 words)\": (300, 400, 800),\n",
        "      \"Long (500-700 words)\": (500, 700, 1400)\n",
        "  }\n",
        "  min_words, max_words, max_tokens = length_map[length_label]\n",
        "\n",
        "  prompt = (\n",
        "      f\"You are a creative writer. Write a {tone.lower()} story based on the following image captions:\"\n",
        "      + \"\\n\".join([f\"- {cap}\" for cap in captions])\n",
        "      + f\" The story should be vivid, engaging, and emotionally rich, with a coherent beginning, middle and end.\"\n",
        "      + f\" Make it approximately between {min_words} and {max_words} words long.\"\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    response = gemini_model.generate_content(\n",
        "        contents=[prompt],\n",
        "        generation_config=genai.GenerationConfig(\n",
        "            temperature=0.9,\n",
        "            top_p=0.95,\n",
        "            max_output_tokens=max_tokens\n",
        "        )\n",
        "    )\n",
        "    # Check if the response contains candidates and if the finish reason is not 'SAFETY'\n",
        "    if response.candidates and response.candidates[0].finish_reason != 2: # Finish reason 2 typically indicates SAFETY\n",
        "        return response.text.strip()\n",
        "    else:\n",
        "        # Provide a more specific message if the response was blocked\n",
        "        return \"Story generation was blocked, possibly due to safety concerns with the content.\"\n",
        "\n",
        "  except Exception as e:\n",
        "      return f\"Error generating story: {e}\"\n",
        "\n",
        "#pdf generation\n",
        "def create_pdf(story_text, images):\n",
        "  buffer = io.BytesIO()\n",
        "  c = canvas.Canvas(buffer, pagesize=A4)\n",
        "  w, h = A4\n",
        "\n",
        "  try:\n",
        "          bg_img = Image.open(requests.get(BACKGROUND_IMAGE_URL, stream=True).raw).convert('RGB')\n",
        "          bg=ImageReader(bg_img)\n",
        "          c.drawImage(bg, 0, 0, width=w, height=h)\n",
        "  except:\n",
        "          pass\n",
        "\n",
        "  c.setFont(\"Helvetica-Bold\", 16)\n",
        "  c.drawString(50,h - 50, \"Generated Story\")\n",
        "\n",
        "  text = textwrap.wrap(story_text, width=100)\n",
        "  y = h - 80\n",
        "  for line in text:\n",
        "          if y < 80:\n",
        "            c.showPage()\n",
        "            y = h - 80\n",
        "          c.drawString(50, y, line)\n",
        "          y -= 15\n",
        "  if images:\n",
        "          c.showPage()\n",
        "          c.setFont(\"Helvetica-Bold\", 16)\n",
        "          c.drawString(50, h - 50, \"Uploaded Images\")\n",
        "          x, y = 50, h - 150\n",
        "          for img in images:\n",
        "              img.thumbnail((200, 200))\n",
        "              c.drawImage(ImageReader(img), x, y, width=200, height=200, preserveAspectRatio=True)\n",
        "              x += 220\n",
        "              if x > w - 50 - 200: # Adjusted condition to prevent image going out of bounds\n",
        "                  x = 50\n",
        "                  y -= 220\n",
        "                  if y < 80: # Check if new row would go off page\n",
        "                      c.showPage()\n",
        "                      y = h - 150\n",
        "                      x = 50 # Reset x for the new page\n",
        "          c.save()\n",
        "          buffer.seek(0)\n",
        "          return buffer\n",
        "\n",
        " # audio generation\n",
        "def create_audio(story):\n",
        "    audio_bytes = io.BytesIO()\n",
        "    tts = gTTS(text=story, lang=\"en\")\n",
        "    tts.write_to_fp(audio_bytes)\n",
        "    audio_bytes.seek(0)\n",
        "    return audio_bytes\n",
        "\n",
        "if st.button(\"Generate Story\", key=\"generate_story_button_1\") and uploaded_images:\n",
        "    if GEMINI_API_KEY: # Only proceed if API key is available\n",
        "        pil_images = [Image.open(img) for img in uploaded_images]\n",
        "        with st.spinner( \"Generating captions...\"):\n",
        "          captions = get_captions(pil_images)\n",
        "          for i, cap in enumerate(captions):\n",
        "              st.write(f\"{i+1}: {cap}\")\n",
        "        with st.spinner(\"Generating story...\"):\n",
        "          story = generated_story(captions, tone, length_label)\n",
        "          st.success(\"Story generated!\")\n",
        "          st.write(story)\n",
        "        with st.spinner(\"Creating PDF...\"):\n",
        "          pdf_file=create_pdf(story, pil_images)\n",
        "          st.download_button(\"Download Story as PDF\", data=pdf_file, file_name=\"generated_story.pdf\", mime=\"application/pdf\")\n",
        "        with st.spinner(\"Creating Audio...\"):\n",
        "          audio_file=create_audio(story)\n",
        "          st.download_button(\"Download Story as MP3\", data=audio_file, file_name=\"generated_story.mp3\", mime=\"audio/mp3\")\n",
        "    else:\n",
        "        st.error(\"Gemini API key is not set. Please set it in your environment variables.\")\n",
        "\n",
        "elif not uploaded_images and st.button(\"Generate Story\", key=\"generate_story_button_2\"): # Added condition to show warning only when button is clicked\n",
        "      st.warning(\"Upload at least one image to begin.\")"
      ],
      "metadata": {
        "id": "SNU3D0BuJpoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af909d11-44c7-4031-e7b9-5d967d34f5ce"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app_streamlit_story.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dbc22aa"
      },
      "source": [
        "!pip install -q streamlit pyngrok transformers torch gtts reportlab Pillow\n",
        "!streamlit run app_streamlit_story.py --server.port 8501 &>/content/log.txt &\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"33XlRRRqPXH9qe5tPEXfviVlTI6_477Si91yBwWMkY51w1vCx\")\n",
        "public_url=ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df07f65c"
      },
      "source": [
        "with open('/content/log.txt', 'r') as f:\n",
        "    print(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z3VbebHukBbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NN8yjriCkBLK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+pVJNYGsmxfZLt5d457Lg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}